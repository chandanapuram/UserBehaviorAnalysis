# -*- coding: utf-8 -*-
"""Assignment solution.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lnICpFHYALIdnZBcOZUcTMIFO-DCGnzC
"""

#importing required libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""# **STEP 1: Loading datasets**"""

#importing dataset
user_details=pd.read_excel('Assignment.xlsx',sheet_name='UserDetails.csv')

user_details

cooking_sessions=pd.read_excel('Assignment.xlsx',sheet_name='CookingSessions.csv')

cooking_sessions

order_details=pd.read_excel('Assignment.xlsx',sheet_name='OrderDetails.csv')

order_details

"""# **STEP 2: Cleaning Datasets**"""

#checking for missing values

print("Missing values in UserDetails:")
print(user_details.isnull().sum())
print("\nMissing values in CookingSessions:")
print(cooking_sessions.isnull().sum())
print("\nMissing values in OrderDetails:")
print(order_details.isnull().sum())

# Handle missing values in OrderDetails (Rating column)
if 'Rating' in order_details.columns:
    mean_rating = order_details['Rating'].mean()
    order_details['Rating'].fillna(mean_rating, inplace=True)
    print(f"Filled missing values in 'rating' column with mean: {mean_rating}")

order_details.isnull().sum()

#checking for duplicates
print("Duplicate rows in UserDetails:")
print(user_details.duplicated().sum())
print("\nDuplicate rows in CookingSessions:")
print(cooking_sessions.duplicated().sum())
print("\nDuplicate rows in OrderDetails:")
print(order_details.duplicated().sum())

# Standardize column names
user_details.columns = user_details.columns.str.lower().str.replace(' ', '_')
cooking_sessions.columns = cooking_sessions.columns.str.lower().str.replace(' ', '_')
order_details.columns = order_details.columns.str.lower().str.replace(' ', '_')

"""# **STEP 3: DATA MERGING**"""

# Merge datasets on user_id
merged_data = pd.merge(user_details, cooking_sessions, on='user_id', how='inner')
merged_data = pd.merge(merged_data, order_details, on='user_id', how='inner')

#column names in merged data
print(merged_data.columns)

# Validate the merged dataset
print("Merged Data Shape:", merged_data.shape)
print(merged_data.head(5))

"""# **STEP 4: Analysis**"""

# Relationship between cooking sessions and orders based on ratings
relation_cooking_order = merged_data.groupby('dish_name_y')[['session_rating', 'rating']].mean()
print("Relationship between Cooking Sessions and Orders:")
print(relation_cooking_order)

# Dishes popularity
popular_cooked = cooking_sessions['dish_name'].value_counts()
print("Popularity of dishes by cooking:")
print(popular_cooked)
popular_ordered = order_details['dish_name'].value_counts()
print("Popularity of ordered dishes by order:")
print(popular_ordered)

# Dishes Popularity based on age
popular_dishes_age = merged_data.groupby('age')['dish_name_y'].value_counts()
print("Dishes popularity by age:")
print(popular_dishes_age)

# Order frequency by age
order_frequency_age = merged_data.groupby('age')['order_id'].count()
print("\nOrder frequency by age:")
print(order_frequency_age)

# Dishes popularity by location
if 'location' in merged_data.columns:
    popular_dishes_location = merged_data.groupby('location')['dish_name_y'].value_counts().groupby('location').head(3)
    print("Dishes popularity by location:")
    print(popular_dishes_location)

"""# **STEP 5: Visualizations**"""

# Correlation between age group and session ratings
age_group_rating_correlation = merged_data.groupby('age')[['session_rating']].mean()
print("Average session rating by age:")
print(age_group_rating_correlation)

# Order frequency vs session ratings
plt.figure(figsize=(8, 5))
sns.scatterplot(data=merged_data, x='rating', y='session_rating', hue='age', palette='viridis')
plt.title('Order Ratings vs. Session Ratings by Age Group')
plt.xlabel('Order Rating')
plt.ylabel('Session Rating')
plt.legend(title='Age', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.savefig('ratings_scatterplot.png')
plt.show()

# Step 5: Visualization
# Popular cooked dishes
plt.figure(figsize=(10, 5))
popular_cooked.head(3).plot(kind='bar', color='skyblue')
plt.title('Top 3 Cooked Dishes')
plt.xlabel('Dish')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('popular_cooked_dishes.png')
plt.show()

# Popular ordered dishes
plt.figure(figsize=(10, 5))
popular_ordered.head(3).plot(kind='bar', color='orange')
plt.title('Top 3 Ordered Dishes')
plt.xlabel('Dish')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('popular_ordered_dishes.png')
plt.show()

# Age group distribution
plt.figure(figsize=(8, 5))
merged_data['age'].value_counts().plot(kind='bar', color='purple')
plt.title('Age Group Distribution')
plt.xlabel('Age Group')
plt.ylabel('Count')
plt.tight_layout()
plt.savefig('age_group_distribution.png')
plt.show()

# Histogram of session ratings
plt.figure(figsize=(8, 5))
merged_data['session_rating'].hist(bins=10, color='green', alpha=0.7)
plt.title('Distribution of Session Ratings')
plt.xlabel('Session Rating')
plt.ylabel('Frequency')
plt.tight_layout()
plt.savefig('session_rating_distribution.png')
plt.show()

# Histogram of order ratings
plt.figure(figsize=(8, 5))
merged_data['rating'].hist(bins=10, color='blue', alpha=0.7)
plt.title('Distribution of Order Ratings')
plt.xlabel('Order Rating')
plt.ylabel('Frequency')
plt.tight_layout()
plt.savefig('order_rating_distribution.png')
plt.show()

# Correlation heatmap for demographic and rating features
plt.figure(figsize=(10, 8))
correlation = merged_data[['age', 'session_rating', 'rating']].corr()
sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap')
plt.tight_layout()
plt.savefig('correlation_heatmap.png')
plt.show()

# Heatmap for cooking vs. ordering ratings
plt.figure(figsize=(8, 6))
sns.heatmap(relation_cooking_order, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Average Ratings: Cooking vs. Ordering')
plt.tight_layout()
plt.savefig('cooking_order_heatmap.png')
plt.show()

# Step 6: Save cleaned data and prepare for GitHub
merged_data.to_csv('Cleaned_Merged_Data.csv', index=False)

print("Analysis complete! Visualizations saved and data prepared.")